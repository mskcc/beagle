name: 'Beagle Services'

x-beagle_celery:
  &beagle_celery
  image:  mskcc/beagle:${BEAGLE_VERSION}
  restart: always
  user: "${DOCKER_UID}:${DOCKER_GID}"
  networks:
    - voyager_net
  env_file: .env
  environment:
    - BEAGLE_DB_URL=beagle_pgbouncer
    - BEAGLE_MEMCACHED_HOST=beagle_memcached
    - BEAGLE_RABBITMQ_URL=beagle_rabbitmq
    - BEAGLE_DB_PORT=5432
    - BEAGLE_MEMCACHED_PORT=11211
    - BEAGLE_RABBITMQ_PORT=5672
    - BEAGLE_LOG_PATH=/beagle/celery/logs/django_server.log
    - BEAGLE_URL=http://$BEAGLE_HOST:$BEAGLE_PORT
  volumes:
    - ./logs/:/beagle/celery/logs/
    - ./celery/:/beagle/celery/
    - ${CLUSTER_FILESYSTEM_MOUNT}:${CLUSTER_FILESYSTEM_MOUNT}
    - ${CLUSTER_FILESYSTEM_SHARE_MOUNT}:${CLUSTER_FILESYSTEM_SHARE_MOUNT}
    - ${CLUSTER_SCRATCH_MOUNT}:${CLUSTER_SCRATCH_MOUNT}
    - ${CLUSTER_FILESYSTEM_COLLAB}:${CLUSTER_FILESYSTEM_COLLAB}
    - ${CLUSTER_FILESYSTEM_TEST}:${CLUSTER_FILESYSTEM_TEST}
  group_add:
    - ${DOCKER_GID}
    - ${GID_FILE_1}
    - ${GID_FILE_2}
    - ${GID_FILE_3}
  post_start:
    - command: useradd --uid ${DOCKER_UID} -m beagle_user
      user: root
  entrypoint: ["/bin/bash","-c"]
  secrets:
    - DB_PASSWORD
    - RABBITMQ_PASSWORD
  healthcheck:
    test: "celery --workdir ${BEAGLE_PATH} -A beagle_etl status || exit 1"
    interval: 30s
    timeout: 3s
    retries: 3
  depends_on:
    beagle_pgbouncer:
      condition: service_healthy
      restart: true
    beagle_postgres:
      condition: service_healthy
      restart: true
    beagle_memcached:
      condition: service_healthy
      restart: false
    beagle_rabbitmq:
      condition: service_healthy
      restart: false
    beagle_celery_beat:
      condition: service_healthy
      restart: false

services:
  beagle_create_volumes:
    image: alpine:3.8
    restart: no
    volumes:
      - ./postgres:/postgres
      - ./pgbouncer:/pgbouncer
      - ./logs:/logs
      - ./celery:/celery
      - ./rabbitmq:/rabbitmq
      - ./server/:/server
      - ./logrotate/:/logrotate
      - ${DB_BACKUP_PATH}:/db_backup
    entrypoint: ["/bin/sh", "-c"]
    command:
    - |
        chown -R ${DOCKER_UID}:${DOCKER_GID} /postgres
        chown -R ${DOCKER_UID}:${DOCKER_GID} /pgbouncer
        chown -R ${DOCKER_UID}:${DOCKER_GID} /logs
        chown -R ${DOCKER_UID}:${DOCKER_GID} /celery
        chown -R ${DOCKER_UID}:${DOCKER_GID} /rabbitmq
        chown -R ${DOCKER_UID}:${DOCKER_GID} /server
        chown -R ${DOCKER_UID}:${DOCKER_GID} /logrotate
        chown -R ${DOCKER_UID}:${DOCKER_GID} /db_backup
  beagle_postgres:
    image: postgres:17
    restart: on-failure
    user: "${DOCKER_UID}:${DOCKER_GID}"
    networks:
      - voyager_net
    volumes:
      - ./postgres/:/var/lib/postgresql/data/
    environment:
      - POSTGRES_USER=${BEAGLE_DB_USERNAME}
      - POSTGRES_PASSWORD=${BEAGLE_DB_PASSWORD}
      - POSTGRES_DB=${BEAGLE_DB_NAME}
    ports:
      - ${BEAGLE_DB_PORT}:5432
    command:
      - -c
      - max_connections=300
      - -c
      - shared_buffers=15GB
      - -c
      - effective_cache_size=45GB
      - -c
      - maintenance_work_mem=2GB
      - -c
      - checkpoint_completion_target=0.9
      - -c
      - wal_buffers=16MB
      - -c
      - default_statistics_target=100
      - -c
      - random_page_cost=1.1
      - -c
      - effective_io_concurrency=200
      - -c
      - work_mem=13107kB
      - -c
      - huge_pages=try
      - -c
      - min_wal_size=2GB
      - -c
      - max_wal_size=8GB
      - -c
      - max_worker_processes=20
      - -c
      - max_parallel_workers_per_gather=4
      - -c
      - max_parallel_workers=20
      - -c
      - max_parallel_maintenance_workers=4
    secrets:
      - DB_PASSWORD
    healthcheck:
      test: ["CMD-SHELL", "sh -c 'pg_isready -U ${BEAGLE_DB_USERNAME} -d ${BEAGLE_DB_NAME} -p 5432'"]
      interval: 30s
      timeout: 3s
      retries: 3
    depends_on:
      - beagle_create_volumes
  beagle_pgbouncer:
    image: edoburu/pgbouncer:latest
    restart: on-failure
    user: "${DOCKER_UID}:${DOCKER_GID}"
    networks:
      - voyager_net
    volumes:
      - ./logs:/logs
      - ./pgbouncer:/etc/pgbouncer
      - type: bind
        source:  /etc/passwd
        target:  /etc/passwd
        read_only: true  
    environment:
      - DB_HOST=beagle_postgres
      - DB_NAME=${BEAGLE_DB_NAME}
      - DB_USER=${BEAGLE_DB_USERNAME}
      - DB_PASSWORD=${BEAGLE_DB_PASSWORD}
      - DB_PORT=5432
      - AUTH_TYPE=plain
    entrypoint: ["/bin/sh","-c"]
    command:
      - |
          INIFILE=/etc/pgbouncer/pgbouncer.ini

          [ -e $$INIFILE ] && rm $$INIFILE

          cp /entrypoint.sh /etc/pgbouncer/entrypoint_mod.sh
                  
          sed -i '/user = postgres/d' /etc/pgbouncer/entrypoint_mod.sh
          /etc/pgbouncer/entrypoint_mod.sh /usr/bin/pgbouncer $$INIFILE > /logs/pgbouncer.log 2>&1
    ports:
        - "5432:5432"
    secrets:
      - DB_PASSWORD
    depends_on:
      beagle_postgres:
        condition: service_healthy
        restart: true
    healthcheck:
      test: ["CMD-SHELL", "sh -c 'pg_isready -h 0.0.0.0 -U ${BEAGLE_DB_USERNAME} -d ${BEAGLE_DB_NAME} -p 5432'"]
      interval: 30s
      timeout: 3s
      retries: 3  
  beagle_memcached:
    image: bitnami/memcached:1.6.37
    restart: on-failure
    user: "${DOCKER_UID}:${DOCKER_GID}"
    networks:
      - voyager_net
    expose:
      - "11211"
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "11211"]
      interval: 30s
      timeout: 5s
      retries: 3 
  beagle_rabbitmq:
    image: rabbitmq:4.0.6-management-alpine
    restart: always
    user: "${DOCKER_UID}:${DOCKER_GID}"
    networks:
      - voyager_net
    volumes:
      - ./rabbitmq/:/var/lib/rabbitmq/
      - ./logs/:/var/log/rabbitmq/
    ports:
      - ${BEAGLE_RABBITMQ_MANAGEMENT_PORT}:15672
      - 5672:5672
    expose:
      - "5672"
    secrets:
      - RABBITMQ_PASSWORD
    environment:
      - RABBITMQ_NODENAME=rabbitmq_beagle
      - RABBITMQ_DEFAULT_USER=${BEAGLE_RABBITMQ_USERNAME}
      - RABBITMQ_DEFAULT_PASS=${BEAGLE_RABBITMQ_PASSWORD}
      - RABBITMQ_LOGS=/var/log/rabbitmq/rabbitmq.log
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "check_running"]
      interval: 30s
      timeout: 3s
      retries: 3
    depends_on:
      - beagle_create_volumes
  beagle:
    image:  mskcc/beagle:${BEAGLE_VERSION}
    restart: always
    user: "${DOCKER_UID}:${DOCKER_GID}"
    networks:
      - voyager_net
    env_file: .env
    environment:
      - BEAGLE_DB_URL=beagle_pgbouncer
      - BEAGLE_MEMCACHED_HOST=beagle_memcached
      - BEAGLE_RABBITMQ_URL=beagle_rabbitmq
      - BEAGLE_DB_PORT=5432
      - BEAGLE_MEMCACHED_PORT=11211
      - BEAGLE_RABBITMQ_PORT=5672
      - BEAGLE_URL=http://$BEAGLE_HOST:$BEAGLE_PORT
      - BEAGLE_LOG_PATH=/beagle/server/django_server.log
    volumes:
      - ./logs/:/beagle/server/
      - ./server:/usr/bin/beagle/static
      - ./server:/staticfiles
      - ${CLUSTER_FILESYSTEM_MOUNT}:${CLUSTER_FILESYSTEM_MOUNT}
      - ${CLUSTER_FILESYSTEM_SHARE_MOUNT}:${CLUSTER_FILESYSTEM_SHARE_MOUNT}
      - ${CLUSTER_SCRATCH_MOUNT}:${CLUSTER_SCRATCH_MOUNT}
      - ${CLUSTER_FILESYSTEM_COLLAB}:${CLUSTER_FILESYSTEM_COLLAB}
      - ${CLUSTER_FILESYSTEM_TEST}:${CLUSTER_FILESYSTEM_TEST}
    group_add:
      - ${DOCKER_GID}
      - ${GID_FILE_1}
      - ${GID_FILE_2}
      - ${GID_FILE_3}
    ports:
      - ${BEAGLE_PORT}:${BEAGLE_PORT}
    secrets:
      - DB_PASSWORD
      - RABBITMQ_PASSWORD
    entrypoint: ["/bin/bash","-c"]
    command: 
      - |
          python3 ${BEAGLE_PATH}/manage.py migrate --noinput
          echo "User.objects.filter(username='admin').exists() or User.objects.create_superuser('admin','voyager@mskcc.org','${BEAGLE_DB_PASSWORD}')" | python3 ${BEAGLE_PATH}/manage.py shell_plus
          python3 ${BEAGLE_PATH}/manage.py collectstatic --noinput
          #ddtrace-run gunicorn beagle.wsgi --log-file $$BEAGLE_LOG_PATH --bind 0.0.0.0:${BEAGLE_PORT} --threads 10 --pythonpath ${BEAGLE_PATH} >> /beagle/server/web_server.log 2>&1
          gunicorn beagle.wsgi --log-file $$BEAGLE_LOG_PATH --bind 0.0.0.0:${BEAGLE_PORT} --threads 10 --pythonpath ${BEAGLE_PATH} >> /beagle/server/web_server.log 2>&1
    healthcheck:
      test: ["CMD-SHELL", "curl -sSf http://localhost:${BEAGLE_PORT}/ || exit 1"]
      interval: 30s
      timeout: 3s
      retries: 3
    depends_on:
      beagle_pgbouncer:
        condition: service_healthy
        restart: true
      beagle_postgres:
        condition: service_healthy
        restart: true
      beagle_memcached:
        condition: service_healthy
        restart: false
      beagle_rabbitmq:
        condition: service_healthy
        restart: false
  beagle_celery_beat:
    <<: *beagle_celery
    command:
      - |           
          PIDFILE=/beagle/celery/beagle.${BEAGLE_DEPLOYMENT}.beagle_beat.pid

          [ -e $$PIDFILE ] && rm $$PIDFILE
          echo 'Running beagle_etl beat...'

          celery --workdir ${BEAGLE_PATH} \
            -A beagle_etl beat \
            -l info \
            -f /beagle/celery/logs/beagle_beat.log \
            --pidfile $$PIDFILE \
            -s /beagle/celery/beagle.${BEAGLE_DEPLOYMENT}.celerybeat-schedule
    healthcheck:
      test: ["CMD-SHELL", "ps -p $(pgrep -F /beagle/celery/beagle.${BEAGLE_DEPLOYMENT}.beagle_beat.pid)"]
      interval: 30s
      timeout: 3s
      retries: 3
    depends_on:
      beagle_pgbouncer:
        condition: service_healthy
        restart: true
      beagle_postgres:
        condition: service_healthy
        restart: true
      beagle_memcached:
        condition: service_healthy
        restart: false
      beagle_rabbitmq:
        condition: service_healthy
        restart: false
  beagle_celery_default_queue:
    <<: *beagle_celery
    command:
      - | 
          PIDFILE=/beagle/celery/beagle.${BEAGLE_DEPLOYMENT}.${BEAGLE_DEFAULT_QUEUE}.pid
          [ -e $$PIDFILE ] && rm $$PIDFILE
          echo 'Running default queue worker...'

          celery --workdir ${BEAGLE_PATH} \
            -A beagle_etl worker \
            -l info \
            -Q ${BEAGLE_DEFAULT_QUEUE} \
            -f /beagle/celery/logs/${BEAGLE_DEFAULT_QUEUE}.log \
            --pidfile $$PIDFILE \
            --concurrency=100 \
            -n beagle.${BEAGLE_DEPLOYMENT}.${BEAGLE_DEFAULT_QUEUE}
  beagle_celery_check_files_queue:
    <<: *beagle_celery
    command:
      - | 
          PIDFILE=/beagle/celery/beagle.${BEAGLE_DEPLOYMENT}.${BEAGLE_CHECK_FILES_QUEUE}.pid
          [ -e $$PIDFILE ] && rm $$PIDFILE
          echo 'Running check files queue worker...'
          
          celery --workdir ${BEAGLE_PATH} \
            -A beagle_etl worker \
            -l info \
            -Q ${BEAGLE_CHECK_FILES_QUEUE} \
            -f /beagle/celery/logs/${BEAGLE_CHECK_FILES_QUEUE}.log \
            --pidfile $$PIDFILE \
            --concurrency=1 \
            -n beagle.${BEAGLE_DEPLOYMENT}.${BEAGLE_CHECK_FILES_QUEUE}
  beagle_celery_job_scheduler_queue:
    <<: *beagle_celery
    command:
      - | 
          PIDFILE=/beagle/celery/beagle.${BEAGLE_DEPLOYMENT}.${BEAGLE_JOB_SCHEDULER_QUEUE}.pid 
          [ -e $$PIDFILE ] && rm $$PIDFILE
          echo 'Running job scheduler queue worker...'
          
          celery --workdir ${BEAGLE_PATH} \
            -A beagle_etl worker \
            -l info \
            -Q ${BEAGLE_JOB_SCHEDULER_QUEUE} \
            -f /beagle/celery/logs/${BEAGLE_JOB_SCHEDULER_QUEUE}.log \
            --pidfile $$PIDFILE \
            --concurrency=1
  beagle_celery_nats_new_request_queue:
    <<: *beagle_celery
    command:
      - | 
          PIDFILE=/beagle/celery/beagle.${BEAGLE_DEPLOYMENT}.${BEAGLE_NATS_NEW_REQUEST_QUEUE}.pid
          [ -e $$PIDFILE ] && rm $$PIDFILE
          echo 'Running nats new request queue worker...'
          
          celery --workdir ${BEAGLE_PATH} \
            -A beagle_etl worker \
            -l debug \
            -Q ${BEAGLE_NATS_NEW_REQUEST_QUEUE} \
            -f /beagle/celery/logs/${BEAGLE_NATS_NEW_REQUEST_QUEUE}.log \
            --pidfile $$PIDFILE \
            --concurrency=1
  beagle_celery_runner_queue:
    <<: *beagle_celery
    command:
      - | 
          PIDFILE=/beagle/celery/beagle.${BEAGLE_DEPLOYMENT}.${BEAGLE_RUNNER_QUEUE}.pid
          [ -e $$PIDFILE ] && rm $$PIDFILE
          echo 'Running runner queue worker...'

           celery --workdir ${BEAGLE_PATH} \
            -A beagle_etl worker \
            -l debug \
            -Q ${BEAGLE_RUNNER_QUEUE} \
            -f /beagle/celery/logs/${BEAGLE_RUNNER_QUEUE}.log \
            --pidfile $$PIDFILE \
            --concurrency=30
  beagle_logrotate:
    image: mskcc/voyager-compose-utils:1.0.0
    restart: always
    user: "${DOCKER_UID}:${DOCKER_GID}"
    networks:
      - voyager_net
    volumes:
      - ./logs:/logs
      - ./logrotate/:/logrotate
    entrypoint: ["/bin/sh", "-c"]
    command:
    - |
        mkdir -p /logs/archive
        cat > /logrotate/logrotate.conf <<EOF
        /logs/*.log
        {
          weekly
          missingok
          minsize ${LOGROTATE_MIN_SIZE}
          maxsize ${LOGROTATE_MAX_SIZE}
          rotate ${LOGROTATE_NUM_ROTATIONS}
          dateext
          olddir /logs/archive
        }
        EOF
        cat > /logrotate/logrotate.cron <<EOF
        ${LOGROTATE_CRON} logrotate --state /logrotate/logrotate.status /logrotate/logrotate.conf
        EOF
        supercronic /logrotate/logrotate.cron >> /logs/logrotate_cron.log 2>&1
    depends_on:
      beagle_celery_beat:
        condition: service_healthy
        restart: false
      beagle_celery_default_queue:
        condition: service_healthy
        restart: false
  beagle_db_backup:
    image: mskcc/voyager-compose-utils:1.0.0
    restart: always
    user: "${DOCKER_UID}:${DOCKER_GID}"
    networks:
      - voyager_net
    volumes:
      - ./logs:/logs
      - ${DB_BACKUP_PATH}:/db_backup
    secrets:
      - DB_PASSWORD
    environment:
      - PGPASSWORD=${BEAGLE_DB_USERNAME}
    entrypoint: ["/bin/sh", "-c"]
    command:
    - |
        mkdir -p /db_backup/archive
        cat > /db_backup/db_backup.cron <<EOF
        ${DB_BACKUP_CRON} python3 /usr/bin/voyager-compose-utils/db_backup.py beagle_backup /db_backup/archive ${DB_BACKUP_MAX} pg_dump beagle_postgres 5432 ${BEAGLE_DB_NAME} ${BEAGLE_DB_USERNAME}
        EOF
        supercronic /db_backup/db_backup.cron >> /logs/db_backup_cron.log 2>&1        
    depends_on:
      beagle_celery_beat:
        condition: service_healthy
        restart: false
      beagle_celery_default_queue:
        condition: service_healthy
        restart: false
networks:
  voyager_net:
    name: voyager_network
    external: true
secrets:
  DB_PASSWORD:
    environment: BEAGLE_DB_PASSWORD
  RABBITMQ_PASSWORD:
    environment: BEAGLE_RABBITMQ_PASSWORD
  