import os
import uuid
from pathlib import Path
from django.conf import settings
from notifier.models import JobGroup
from file_system.models import File, FileGroup, FileType
from runner.models import Pipeline, Run
from runner.operator.operator import Operator
from runner.run.objects.run_creator_object import RunCreator
from runner.operator.argos_operator.v1_2_0.argos_operator import build_data_list, get_samples_from_data


class AtlantisOperator(Operator):
    ARGOS_NAME = "argos"
    ARGOS_VERSION = "1.1.2"

    def get_jobs(self):
        # load references

        input_json = self.construct_inputs_jsons()
        files = self.get_files()
        data = build_data_list(files)
        samples = get_samples_from_data(data)

        # Take fastqs for tumors and attach metadata so that it's accepted by bwa-men

        # The Atlantis pipeline will then align these tumors into bams and compare them
        # against dmp normals directory and this request's normalsn


        # If we go by bam - i.e., Runs generated by the alignment_pair_operator - we would only need
        # the run_ids of all the Runs generating the bam and retrieve the tumor_bam path
        input_jsons_list = list() #contains one input json per tumor

        for run_id in self.run_ids:
            run = Run.objects.get(id=run_id)
            tumor_bam_sample_name = run.tags["sampleNameTumor"]
            tumor_bam_path = self.get_tumor_bam_path_from_run(run)
            input_json = self.create_input_json(tumor_bam_path)
            input_jsons_list.append(input_json)

        for input_json in input_jsons_list:
            name = "Some name here"
        # to be continued
    


    def get_tumor_bam_path_from_run(run):
        ports = Port.filter

        # return one File (tumor bam)

    def create_input_json(tumor_bam_path):
        references = self.load_references()
        input_json = dict()
        input_json["tumor_bam"] = {"location": "juno://" + tumor_bam_path, "class": "File" } 
        input_json.update(references)
        return input_json

    def construct_inputs_jsons(self):
        request_id=self.request_id

        references = self.load_references()
        """
        For every sample/tumor in this request, create an Atlantis Run for each
        """


    def get_files(self):
        files = FileRepository.filter(
            queryset=self.files,
            metadata={settings.REQUEST_ID_METADATA_KEY: self.request_id, settings.IGO_COMPLETE_METADATA_KEY: True},
            filter_redact=True,
        )

        return files
